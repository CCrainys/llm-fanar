name:
compute:
  gpus: 8
  cluster:
scheduling:
  priority: low
  preemptible: true
image: mosaicml/llm-foundry:2.1.0_cu121-8e96a95
integrations:
- integration_type: git_repo
  git_repo: mosaicml/llm-foundry
  git_branch: main
  pip_install: .[gpu-flash2]
  ssh_clone: true

command: |-
  cd llm-foundry/scripts
  composer eval/eval.py /mnt/config/parameters.yaml  || \
  (echo "Command failed - killing python" && pkill python && exit 1)
parameters:
  model_name:
  model_path:
  max_seq_len: 4096
  models:
  - model_name:
    model:
      name: hf_causal_lm
      pretrained: true
      init_device: mixed
      use_auth_token: true
      use_flash_attention_2: true
      pretrained_model_name_or_path:
    tokenizer:
      name:
      kwargs:
        model_max_length: 4096
  icl_tasks:
  -
    label: jeopardy
    dataset_uri: eval/local_data/world_knowledge/jeopardy_all.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
    continuation_delimiter: "\nAnswer: "
    has_categories: true
  -
    label: bigbench_qa_wikidata
    dataset_uri: eval/local_data/world_knowledge/bigbench_qa_wikidata.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: arc_easy
    dataset_uri: eval/local_data/world_knowledge/arc_easy.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
    continuation_delimiter: "\nAnswer: "
  -
    label: arc_challenge
    dataset_uri: eval/local_data/world_knowledge/arc_challenge.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
    continuation_delimiter: "\nAnswer: "
  -
    label: mmlu
    dataset_uri: eval/local_data/world_knowledge/mmlu.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
    continuation_delimiter: "\nAnswer: "
    has_categories: true
  -
    label: bigbench_misconceptions
    dataset_uri: eval/local_data/world_knowledge/bigbench_misconceptions.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: copa
    dataset_uri: eval/local_data/commonsense_reasoning/copa.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: piqa
    dataset_uri: eval/local_data/commonsense_reasoning/piqa.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
    continuation_delimiter: "\nAnswer: "
  -
    label: openbook_qa
    dataset_uri: eval/local_data/commonsense_reasoning/openbook_qa.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: bigbench_novel_concepts
    dataset_uri: eval/local_data/commonsense_reasoning/bigbench_novel_concepts.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: bigbench_strange_stories
    dataset_uri: eval/local_data/commonsense_reasoning/bigbench_strange_stories.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: bigbench_strategy_qa
    dataset_uri: eval/local_data/commonsense_reasoning/bigbench_strategy_qa.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: lambada_openai
    dataset_uri: eval/local_data/language_understanding/lambada_openai.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: hellaswag
    dataset_uri: eval/local_data/language_understanding/hellaswag.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: winograd
    dataset_uri: eval/local_data/language_understanding/winograd_wsc.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: schema
  -
    label: winogrande
    dataset_uri: eval/local_data/language_understanding/winogrande.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: schema
  -
    label: bigbench_conlang_translation
    dataset_uri: eval/local_data/language_understanding/bigbench_conlang_translation.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: bigbench_language_identification
    dataset_uri: eval/local_data/language_understanding/bigbench_language_identification.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: bigbench_conceptual_combinations
    dataset_uri: eval/local_data/language_understanding/bigbench_conceptual_combinations.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: bigbench_elementary_math_qa
    dataset_uri: eval/local_data/symbolic_problem_solving/bigbench_elementary_math_qa.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: bigbench_dyck_languages
    dataset_uri: eval/local_data/symbolic_problem_solving/bigbench_dyck_languages.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: bigbench_cs_algorithms
    dataset_uri: eval/local_data/symbolic_problem_solving/bigbench_cs_algorithms.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: bigbench_logical_deduction
    dataset_uri: eval/local_data/symbolic_problem_solving/bigbench_logical_deduction.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: bigbench_operators
    dataset_uri: eval/local_data/symbolic_problem_solving/bigbench_operators.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: bigbench_repeat_copy_logic
    dataset_uri: eval/local_data/symbolic_problem_solving/bigbench_repeat_copy_logic.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: simple_arithmetic_nospaces
    dataset_uri: eval/local_data/symbolic_problem_solving/simple_arithmetic_nospaces.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: simple_arithmetic_withspaces
    dataset_uri: eval/local_data/symbolic_problem_solving/simple_arithmetic_withspaces.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: math_qa
    dataset_uri: eval/local_data/symbolic_problem_solving/math_qa.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: logi_qa
    dataset_uri: eval/local_data/symbolic_problem_solving/logi_qa.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
    continuation_delimiter: "\nAnswer: "
  -
    label: pubmed_qa_labeled
    dataset_uri: eval/local_data/reading_comprehension/pubmed_qa_labeled.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: squad
    dataset_uri: eval/local_data/reading_comprehension/squad.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: language_modeling
  -
    label: bigbench_understanding_fables
    dataset_uri: eval/local_data/reading_comprehension/bigbench_understanding_fables.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
  -
    label: boolq
    dataset_uri: eval/local_data/reading_comprehension/boolq.jsonl
    num_fewshot: [0, 1, 3, 5, 10]
    icl_task_type: multiple_choice
    continuation_delimiter: "\nAnswer: "
  device_eval_batch_size: 1
  seed: 42
  precision: amp_bf16
  dist_timeout: 7200
  fsdp_config:
    verbose: false
    mixed_precision: PURE
    limit_all_gathers: true
    sharding_strategy: FULL_SHARD
    activation_cpu_offload: false
    activation_checkpointing: true
    activation_checkpointing_reentrant: false
  loggers:
    wandb: {}
